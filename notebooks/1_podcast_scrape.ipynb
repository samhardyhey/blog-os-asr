{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab55a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T00:44:50.013352Z",
     "start_time": "2021-09-03T00:44:49.574687Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from mutagen.mp3 import MP3\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import ftfy\n",
    "\n",
    "\n",
    "def remove_excess_char(\n",
    "    input_string: str,\n",
    ") -> str:\n",
    "    # new lines\n",
    "    text = re.sub(\"[\\n]{2,}\", \"\\n\", input_string)\n",
    "\n",
    "    # tabs\n",
    "    text = re.sub(\"[\\t]{2,}\", \"\\t\", text)\n",
    "\n",
    "    # carriage returns\n",
    "    text = re.sub(\"[\\r]{2,}\", \"\\r\", text)\n",
    "\n",
    "    # vertical tabs\n",
    "    text = re.sub(\"[\\v]{2,}\", \"\\v\", text)\n",
    "\n",
    "    # n-repetitive spaces\n",
    "    for n in range(2, 10)[::-1]:\n",
    "        text = text.replace(\" \" * n, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_html_tags(string: str) -> str:\n",
    "    soup = BeautifulSoup(string, \"html.parser\")\n",
    "    return soup.get_text(separator=\" \")\n",
    "\n",
    "def remove_malformed_utf8(string: str) -> str:\n",
    "    return ftfy.fix_text(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "577a8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "pod_scrape_logger = logging.getLogger(\"pod_scrape_logger\")\n",
    "pod_scrape_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate trove podcasts\n",
    "trove_a = pd.read_csv(\n",
    "    \"/home/samhardyhey/experiment_artefacts/stt_training/misc_data/radio_national_trove_results.csv\"\n",
    ")\n",
    "\n",
    "trove_b = pd.read_csv(\n",
    "    \"/home/samhardyhey/experiment_artefacts/stt_training/misc_data/radio_national_trove_results_v2.csv\"\n",
    ")\n",
    "\n",
    "trove_all = (\n",
    "    pd.concat([trove_a, trove_b])\n",
    "    .drop_duplicates(\"id\")\n",
    "    .pipe(lambda x: x[x.abc_site_link.str.contains(\"/programs/\")])\n",
    ")\n",
    "\n",
    "# consolidate all URLS\n",
    "# all_podcast_urls = list(set(most_recent + trove_all.abc_site_link.tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e42cbf",
   "metadata": {},
   "source": [
    "## Audio/transcript retrieval\n",
    "- Retrieve 100 most recent podcasts from RN page\n",
    "- Use additional podcasts retrieved via Trove\n",
    "- Consolidate/filter web addreses, retrieve audio and transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfeaf31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T00:18:43.742859Z",
     "start_time": "2021-09-02T00:18:43.737593Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_abc_podcast_transcript_and_mp3(podcast_url, audio_dir, transcript_dir):\n",
    "    # throttle prevention?\n",
    "    #     sleep(0.05)\n",
    "\n",
    "    file_name = (\n",
    "        podcast_url.split(\"programs/\")[1]\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(\" \", \"-\")\n",
    "        .replace(\",\", \"\")\n",
    "    )\n",
    "\n",
    "    if (audio_dir / f\"{file_name}.mp3\").exists() or (\n",
    "        audio_dir / transcript_dir / f\"{file_name}.txt\"\n",
    "    ).exists():\n",
    "        #         print(f\"Audio/transcript already exists for: {podcast_url}\")\n",
    "        pass\n",
    "    else:\n",
    "        page = requests.get(podcast_url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        # attempt to retrieve audio\n",
    "        try:\n",
    "            results = soup.find(id=\"comp-audio-player5\")\n",
    "            mp3_url = results.find_all(\"a\")[0][\"href\"]\n",
    "            # download and save mp3\n",
    "            doc = requests.get(mp3_url)\n",
    "            with open(audio_dir / f\"{file_name}.mp3\", \"wb\") as f:\n",
    "                f.write(doc.content)\n",
    "        except:\n",
    "            pass\n",
    "        #             print(f\"Unable to retrieve audio for: {podcast_url}\")\n",
    "\n",
    "        # attempt to retrieve transcript\n",
    "        try:\n",
    "            results = soup.find(\n",
    "                \"div\", class_=\"view-transcript comp-accordion-wrapper\"\n",
    "            ).find(\"div\", class_=\"comp-rich-text clearfix\")\n",
    "            transcript = results.get_text(separator=\"\\n\")\n",
    "            with open(transcript_dir / f\"{file_name}.txt\", \"w\") as f:\n",
    "                f.write(transcript)\n",
    "        except:\n",
    "            pass\n",
    "#             print(f\"Unable to retrieve transcript for: {podcast_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urlsplit\n",
    "from pathlib import Path\n",
    "\n",
    "import shutil\n",
    "\n",
    "output_dir = Path(\"../output/abc_podcasts\")\n",
    "shutil.rmtree(str(output_dir)) if output_dir.exists() else None\n",
    "output_dir.mkdir(parents=True)\n",
    "\n",
    "# get most recent podcasts from RN website\n",
    "url = \"https:/www.abc.net.au/radionational/transcripts/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "transcript_page_urls = []\n",
    "for a in soup.find_all(\"a\", href=True):\n",
    "    if \"/radionational/programs\" in a[\"href\"] and len(Path(a[\"href\"]).parts) > 3:\n",
    "        transcript_page_urls.append(f\"https:/www.abc.net.au{a['href']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07715b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(transcript_page_urls[0])\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "def get_podcast_mp3_link(page_soup):\n",
    "    audio_elements = page_soup.find('audio')\n",
    "    mp3_candidate_links = [e['src'] for e in audio_elements]\n",
    "\n",
    "    if len(mp3_candidate_links) > 1:\n",
    "        pod_scrape_logger.warning(\"More than 1 candidate mp3 URL found\")\n",
    "    else:\n",
    "        return mp3_candidate_links[0]\n",
    "\n",
    "def download_podcast_mp3(mp3_url, audio_dir, file_name):\n",
    "    doc = requests.get(mp3_url)\n",
    "    with open(audio_dir / f\"{file_name}.mp3\", \"wb\") as f:\n",
    "        f.write(doc.content)\n",
    "\n",
    "def get_podcast_transcript(page_soup):\n",
    "    results = page_soup.find(id='transcript')\n",
    "    return results.get_text(separator=\"\\n\")\n",
    "\n",
    "mp3_link = get_podcast_mp3_link(soup)\n",
    "transcript_rough = get_podcast_transcript(soup)\n",
    "\n",
    "download_podcast_mp3(mp3_link, output_dir, Path(transcript_page_urls[0]).parents[0].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf3cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3fa38322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6eba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T00:45:53.432453Z",
     "start_time": "2021-09-03T00:45:53.429149Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_dir = Path(\n",
    "    \"/home/samhardyhey/experiment_artefacts/stt_training/exp_a/sh_abc_podcasts/audio\"\n",
    ")\n",
    "transcript_dir = Path(\n",
    "    \"/home/samhardyhey/experiment_artefacts/stt_training/exp_a/sh_abc_podcasts/transcripts\"\n",
    ")\n",
    "\n",
    "audio_dir.mkdir(parents=True, exist_ok=True) if audio_dir.exists() == False else None\n",
    "transcript_dir.mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ") if transcript_dir.exists() == False else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630b08b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-02T00:16:31.241Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for podcast_url in tqdm(all_podcast_urls):\n",
    "    try:\n",
    "        get_abc_podcast_transcript_and_mp3(\n",
    "            podcast_url, audio_dir, transcript_dir)\n",
    "    except:\n",
    "        print(f\"Could not download page contents for: {podcast_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb6a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:19:03.794252Z",
     "start_time": "2021-09-01T05:19:03.790731Z"
    }
   },
   "source": [
    "## Post-processing\n",
    "- Remove audio/transcripts which are missing either an audio/transcript file (incomplete)\n",
    "- Clean transcripts, remove speaker tags\n",
    "- Remove podcasts with slow/fast WPM/speaker rates\n",
    "- Remove very short/long podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded1c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T00:46:01.606039Z",
     "start_time": "2021-09-03T00:46:01.554407Z"
    }
   },
   "outputs": [],
   "source": [
    "# get intersection\n",
    "all_audio = set([e.stem for e in audio_dir.rglob(\"./*.mp3\")])\n",
    "all_transcript = set([e.stem for e in transcript_dir.rglob(\"./*.txt\")])\n",
    "complete_transcripts = all_audio.intersection(all_transcript)\n",
    "\n",
    "# remove files not in intersection\n",
    "for e in audio_dir.rglob(\"./*.mp3\"):\n",
    "    if e.stem not in complete_transcripts:\n",
    "        os.remove(e.as_posix())\n",
    "\n",
    "# remove files not in intersection\n",
    "for e in transcript_dir.rglob(\"./*.txt\"):\n",
    "    if e.stem not in complete_transcripts:\n",
    "        os.remove(e.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b45da0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T00:46:14.555359Z",
     "start_time": "2021-09-03T00:46:14.552531Z"
    }
   },
   "outputs": [],
   "source": [
    "transcript_processed_dir = Path(\n",
    "    \"/home/samhardyhey/experiment_artefacts/stt_training/exp_a/sh_abc_podcasts/transcripts_processed\"\n",
    ")\n",
    "transcript_processed_dir.mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ") if transcript_processed_dir.exists() == False else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a40b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:34:44.673269Z",
     "start_time": "2021-09-03T01:34:44.669137Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_speaker_tags(text):\n",
    "    # v2, iterate through each line in the transcript, discard and strip => rejoin\n",
    "    filtered = []\n",
    "    for e in text.replace(\"\\n:\", \":\\n\").split(\"\\n\"):\n",
    "        # weirdo newline characters\n",
    "        e = e.strip()\n",
    "\n",
    "        # if colon in first 20 char of each new line, split on colon (speaker tag, probably)\n",
    "        if \":\" in e[:20]:\n",
    "            e = e.split(\":\")[1].strip()\n",
    "\n",
    "        # remove production audio overlay brackets/parens\n",
    "        if \"[\" in e:\n",
    "            e = re.sub(\"\\[(.*?)\\]\", \"\", e)\n",
    "\n",
    "        if \"(\" in e:\n",
    "            e = re.sub(\"\\(.*?\\)\", \"\", e)\n",
    "\n",
    "        # additionally, any excessive characters\n",
    "        e = remove_excess_char(e)\n",
    "\n",
    "        if len(e) == 0:\n",
    "            # zero length\n",
    "            continue\n",
    "\n",
    "        if e.endswith(\":\"):\n",
    "            # probably a speaker utterance mark\n",
    "            continue\n",
    "\n",
    "        filtered.append(e)\n",
    "\n",
    "    return \" \".join(filtered)  # concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6dda5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:03:08.022058Z",
     "start_time": "2021-09-03T01:03:08.011972Z"
    }
   },
   "outputs": [],
   "source": [
    "# transcript post-processing debugging\n",
    "# import random\n",
    "\n",
    "# from srsly import read_jsonl\n",
    "\n",
    "# train_manifest = (pd.DataFrame(\n",
    "#     list(read_jsonl('/home/samhardyhey/experiment_artefacts/stt_training/exp_b/data/output/train_manifest.json')))\n",
    "#                  .assign(stem=lambda x: x.audio_filepath.apply(lambda y: Path(y).stem))\n",
    "#                   .pipe(lambda x: x[x.text_no_preprocessing.str.contains('Craig')])\n",
    "#                  )\n",
    "\n",
    "# with open('/home/samhardyhey/experiment_artefacts/stt_training/exp_b/data/output/manifests/', 'r') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# for e in random.sample(list(transcript_dir.rglob('./*.txt')), 10):\n",
    "# #     if 'breakfast_economists-warning-to-the-rba-dont-raise-interest_2961146' in e.stem:\n",
    "#     with open(e, 'r') as f:\n",
    "#         text = f.read()\n",
    "#         print()\n",
    "#         print()\n",
    "#         print(text[:400])\n",
    "#         print()\n",
    "#         removed_tags = remove_speaker_tags(text)\n",
    "#         print(removed_tags[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f073a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:36:48.595432Z",
     "start_time": "2021-09-03T01:36:43.875325Z"
    }
   },
   "outputs": [],
   "source": [
    "for e in transcript_dir.rglob(\"./*.txt\"):\n",
    "    # open, strip\n",
    "    with open(e, \"r\") as f:\n",
    "        text = f.read()\n",
    "    removed_tags = remove_speaker_tags(text)\n",
    "\n",
    "    # save\n",
    "    with open(transcript_processed_dir / f\"{e.stem}.txt\", \"w\") as f:\n",
    "        res = f.write(removed_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2385a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:36:57.505750Z",
     "start_time": "2021-09-03T01:36:51.494279Z"
    }
   },
   "outputs": [],
   "source": [
    "# additionally, remove very/short podcasts with disproportionate WPM counts\n",
    "transcript_records = []\n",
    "for audio, transcript in zip(\n",
    "    sorted(list(audio_dir.rglob(\"./*.mp3\"))),\n",
    "    sorted(list(transcript_processed_dir.rglob(\"./*.txt\"))),\n",
    "):\n",
    "    assert audio.stem == transcript.stem\n",
    "\n",
    "    with open(transcript, \"r\") as f:\n",
    "        transcript_text = f.read()\n",
    "\n",
    "    transcript_records.append(\n",
    "        {\n",
    "            \"transcript\": transcript_text,\n",
    "            \"audio_len\": MP3(audio).info.length,\n",
    "            \"audio_path\": audio,\n",
    "            \"transcript_path\": transcript,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d0361",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T06:00:16.868204Z",
     "start_time": "2021-09-01T06:00:16.866066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average WPM/speaking rates - https:/virtualspeech.com/blog/average-speaking-rate-words-per-minute\n",
    "# Presentations: between 100 - 150 wpm for a comfortable pace\n",
    "# Conversational: between 120 - 150 wpm\n",
    "# Audiobooks: between 150 - 160 wpm, which is the upper range that people comfortably hear and vocalise words\n",
    "# Radio hosts and podcasters: between 150 - 160 wpm\n",
    "# Auctioneers: can speak at about 250 wpm\n",
    "# Commentators: between 250- 400 wpm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ec107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:36:59.164907Z",
     "start_time": "2021-09-03T01:36:58.937448Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_podcast_meta = (\n",
    "    pd.DataFrame(transcript_records)\n",
    "    .assign(stem=lambda x: x.audio_path.apply(lambda y: y.stem))\n",
    "    .assign(transcript_len=lambda x: x.transcript.apply(lambda y: len(y.split(\" \"))))\n",
    "    # enforce podcast min/max length\n",
    "    .assign(audio_len_min=lambda x: x.audio_len.apply(lambda y: y / 60))\n",
    "    .query(\"audio_len_min >= 5 & audio_len_min <= 30\")\n",
    "    # enforce average floor/ceiling on WPM rates\n",
    "    .assign(\n",
    "        wpm=lambda x: x.apply(lambda y: y.transcript_len / (y.audio_len / 60), axis=1)\n",
    "    )\n",
    "    .query(\"wpm >= 120 & wpm <= 180\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1077bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:34:11.318107Z",
     "start_time": "2021-09-03T01:34:11.314937Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(filtered_podcast_meta.iloc[999].transcript_path, \"r\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66afc56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T00:26:47.339661Z",
     "start_time": "2021-09-02T00:26:47.318406Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    filtered_podcast_meta.pipe(\n",
    "        lambda x: x[[\"audio_len\", \"transcript_len\", \"audio_len_min\", \"wpm\"]]\n",
    "    ).describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e732407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T00:25:50.075979Z",
     "start_time": "2021-09-02T00:25:50.044500Z"
    }
   },
   "outputs": [],
   "source": [
    "len(list(audio_dir.rglob(\"./*.mp3\")))\n",
    "len(list(transcript_dir.rglob(\"./*.txt\")))\n",
    "len(list(transcript_processed_dir.rglob(\"./*.txt\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a76f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:38:17.080049Z",
     "start_time": "2021-09-03T01:38:16.747000Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove files not within final query\n",
    "for e in audio_dir.rglob(\"./*.mp3\"):\n",
    "    if e.stem not in set(filtered_podcast_meta.stem):\n",
    "        os.remove(e.as_posix())\n",
    "\n",
    "for e in transcript_dir.rglob(\"./*.txt\"):\n",
    "    if e.stem not in set(filtered_podcast_meta.stem):\n",
    "        os.remove(e.as_posix())\n",
    "\n",
    "for e in transcript_processed_dir.rglob(\"./*.txt\"):\n",
    "    if e.stem not in set(filtered_podcast_meta.stem):\n",
    "        os.remove(e.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3e4cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T01:38:21.395806Z",
     "start_time": "2021-09-03T01:38:21.376032Z"
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "set([e.stem for e in audio_dir.rglob(\"./*.mp3\")]) == set(\n",
    "    [e.stem for e in transcript_processed_dir.rglob(\"./*.txt\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beeff94",
   "metadata": {},
   "source": [
    "## Prior meta analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce88e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = duration / 3600\n",
    "mins = (duration - (hrs * 3600)) / 60\n",
    "seconds = duration - (hrs * 3600) - (mins * 60)\n",
    "\n",
    "f\"{int(hrs)}:{int(mins)}:{seconds}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3s = glob(\n",
    "    \"/home/rianne/-data/experiment_artefacts/stt_training/exp_b/abc_podcasts/**/**/*.mp3\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113309e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = []\n",
    "for mp3 in mp3s:\n",
    "    audio = MP3(mp3).info.length\n",
    "    duration.append(audio.info.length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_transcript_len(mp3_loc):\n",
    "    text_loc = mp3_loc.replace(\"/audio/\", \"/text/\").replace(\".mp3\", \".txt\")\n",
    "\n",
    "    with open(text_loc) as f:\n",
    "        lines = f.read()\n",
    "    return len(lines.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368fa22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mp3s, columns=[\"mp3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c11401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"n_words\"] = df[\"mp3\"].apply(cal_transcript_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167834a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"audio_len\"] = df[0].apply(lambda x: MP3(x).info.length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df.query(\"audio_len < 2000\").query(\"n_words < 7000\")\n",
    "small_df = small_df[~((small_df.audio_len < 400) & (small_df.n_words > 2200))]\n",
    "small_df = small_df[~((small_df.audio_len > 1500) & (small_df.n_words < 500))]\n",
    "\n",
    "small_df.plot.scatter(x=\"n_words\", y=\"audio_len\", c=\"DarkBlue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = small_df.audio_len.sum()\n",
    "\n",
    "hrs = duration / 3600\n",
    "mins = (duration - (hrs * 3600)) / 60\n",
    "seconds = duration - (hrs * 3600) - (mins * 60)\n",
    "\n",
    "f\"{int(hrs)}:{int(mins)}:{seconds}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625e462",
   "metadata": {},
   "source": [
    "# Remove outliers & long podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = {Path(f).stem for f in df[0].tolist()}\n",
    "keep_files = {Path(f).stem for f in small_df[0].tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_files = all_files.difference(keep_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "incorrect_files = list(remove_files)\n",
    "\n",
    "for file in incorrect_files:\n",
    "    try:\n",
    "        os.remove(\n",
    "            f\"/home/rianne/-data/experiment_artefacts/stt_training/exp_a/abc_podcasts/transformed/text_with_speaker_tags/{file}.txt\"\n",
    "        )\n",
    "        os.remove(\n",
    "            f\"/home/rianne/-data/experiment_artefacts/stt_training/exp_a/abc_podcasts/transformed/text_no_speaker_tags/{file}.txt\"\n",
    "        )\n",
    "        os.remove(\n",
    "            f\"/home/rianne/-data/experiment_artefacts/stt_training/exp_a/abc_podcasts/transformed/audio/{file}.mp3\"\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Could not remove file {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blog.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b352da5c727154a09156c935f17a9c4d49b2c9c0946f47ddfcca219f38b45087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
