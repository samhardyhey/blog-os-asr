{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import ftfy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from mutagen.mp3 import MP3\n",
    "from tqdm import tqdm\n",
    "\n",
    "pod_scrape_logger = logging.getLogger(\"pod_scrape_logger\")\n",
    "pod_scrape_logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def remove_excess_char(\n",
    "    input_string: str,\n",
    ") -> str:\n",
    "    # new lines\n",
    "    text = re.sub(\"[\\n]{2,}\", \"\\n\", input_string)\n",
    "\n",
    "    # tabs\n",
    "    text = re.sub(\"[\\t]{2,}\", \"\\t\", text)\n",
    "\n",
    "    # carriage returns\n",
    "    text = re.sub(\"[\\r]{2,}\", \"\\r\", text)\n",
    "\n",
    "    # vertical tabs\n",
    "    text = re.sub(\"[\\v]{2,}\", \"\\v\", text)\n",
    "\n",
    "    # n-repetitive spaces\n",
    "    for n in range(2, 10)[::-1]:\n",
    "        text = text.replace(\" \" * n, \" \")\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_podcast_page_urls(page_url, base_url):\n",
    "    res = requests.get(page_url)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    podcast_page_urls = []\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        if \"/radionational/programs\" in a[\"href\"] and len(Path(a[\"href\"]).parts) > 3:\n",
    "            podcast_page_urls.append(f\"{base_url}{a['href']}\")\n",
    "    return podcast_page_urls\n",
    "\n",
    "\n",
    "def get_podcast_mp3_link(page_soup):\n",
    "    audio_elements = page_soup.find(\"audio\")\n",
    "    mp3_candidate_links = [e[\"src\"] for e in audio_elements]\n",
    "\n",
    "    if len(mp3_candidate_links) > 1:\n",
    "        pod_scrape_logger.warning(\"More than 1 candidate mp3 URL found\")\n",
    "    else:\n",
    "        return mp3_candidate_links[0]\n",
    "\n",
    "\n",
    "def download_podcast_mp3(mp3_url, audio_dir, file_name):\n",
    "    doc = requests.get(mp3_url)\n",
    "    with open(audio_dir / f\"{file_name}.mp3\", \"wb\") as f:\n",
    "        f.write(doc.content)\n",
    "\n",
    "\n",
    "def get_podcast_transcript(page_soup):\n",
    "    results = page_soup.find(id=\"transcript\")\n",
    "    return results.get_text(separator=\"\\n\")\n",
    "\n",
    "\n",
    "def remove_speaker_tags(transcript):\n",
    "    filtered = []\n",
    "    for line in transcript.replace(\"\\n:\", \":\\n\").split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "\n",
    "        # colon in initial fragment > speaker tag probably\n",
    "        if \":\" in line[:20]:\n",
    "            line = line.split(\":\")[1].strip()\n",
    "\n",
    "        # remove production audio overlay brackets/parens\n",
    "        if \"[\" in line:\n",
    "\n",
    "            line = re.sub(\"\\[(.*?)\\]\", \"\", line)\n",
    "\n",
    "        if \"(\" in line:\n",
    "            line = re.sub(\"\\(.*?\\)\", \"\", line)\n",
    "\n",
    "        line = remove_excess_char(line)\n",
    "\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "\n",
    "        if line.endswith(\":\"):\n",
    "            # probably a speaker utterance mark\n",
    "            continue\n",
    "\n",
    "        filtered.append(line)\n",
    "\n",
    "    return \" \".join(filtered)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07715b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate output dirs for audio/transcripts\n",
    "audio_output_dir = Path(\"../output/radio_national_podcasts/audio\")\n",
    "shutil.rmtree(str(audio_output_dir)) if audio_output_dir.exists() else None\n",
    "audio_output_dir.mkdir(parents=True)\n",
    "\n",
    "transcript_output_dir = Path(\"../output/radio_national_podcasts/transcripts\")\n",
    "shutil.rmtree(str(transcript_output_dir)) if transcript_output_dir.exists() else None\n",
    "transcript_output_dir.mkdir(parents=True)\n",
    "\n",
    "# get most recent podcasts from RN website\n",
    "base_url = \"https://www.abc.net.au\"\n",
    "page_url = \"https://www.abc.net.au/radionational/transcripts/\"\n",
    "\n",
    "podcast_page_urls = get_podcast_page_urls(page_url, base_url)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3e24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for podcast_page_url in tqdm(\n",
    "    podcast_page_urls[:5], desc=f\"Downloading podcasts/transcripts for {page_url}\"\n",
    "):\n",
    "    res = requests.get(podcast_page_url)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    mp3_link = get_podcast_mp3_link(soup)\n",
    "    download_podcast_mp3(\n",
    "        mp3_link, audio_output_dir, Path(podcast_page_url).parents[0].name\n",
    "    )\n",
    "\n",
    "    transcript_rough = get_podcast_transcript(soup)\n",
    "    transcript_cleaned = remove_speaker_tags(transcript_rough)\n",
    "\n",
    "    with open(\n",
    "        transcript_output_dir / f\"{Path(podcast_page_url).parents[0].name}.txt\", \"w\"\n",
    "    ) as f:\n",
    "        f.write(transcript_cleaned)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb6a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:19:03.794252Z",
     "start_time": "2021-09-01T05:19:03.790731Z"
    }
   },
   "source": [
    "## Post-processing\n",
    "- Remove audio/transcripts which are missing either an audio/transcript file (incomplete)\n",
    "- Clean transcripts, remove speaker tags\n",
    "- Remove podcasts with slow/fast WPM/speaker rates\n",
    "- Remove very short/long podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded1c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T00:46:01.606039Z",
     "start_time": "2021-09-03T00:46:01.554407Z"
    }
   },
   "outputs": [],
   "source": [
    "def prune_pairless_transcripts(audio_output_dir, transcript_output_dir):\n",
    "    # get intersection\n",
    "    all_audio = set([e.stem for e in audio_output_dir.glob(\"./*.mp3\")])\n",
    "    all_transcript = set([e.stem for e in transcript_output_dir.glob(\"./*.txt\")])\n",
    "    intersecting_transcripts = all_audio.intersection(all_transcript)\n",
    "\n",
    "    for file in audio_output_dir.glob(\"./*.mp3\"):\n",
    "        if file.stem not in intersecting_transcripts:\n",
    "            pod_scrape_logger.warning(\n",
    "                f\"Could not find {file.name} in audio/transcript intersection; removing\"\n",
    "            )\n",
    "            file.unlink()\n",
    "\n",
    "    for file in transcript_output_dir.glob(\"./*.txt\"):\n",
    "        if file.stem not in intersecting_transcripts:\n",
    "            pod_scrape_logger.warning(\n",
    "                f\"Could not find {file.name} in audio/transcript intersection; removing\"\n",
    "            )\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def prune_transcripts_not_in_manifest(\n",
    "    manifest, audio_output_dir, transcript_output_dir\n",
    "):\n",
    "    audio_file_names = [e.name for e in manifest.audio_path]\n",
    "    transcript_file_names = [e.name for e in manifest.transcript_path]\n",
    "\n",
    "    for file in audio_output_dir.glob(\"./*.mp3\"):\n",
    "        if file.name not in audio_file_names:\n",
    "            pod_scrape_logger.warning(\n",
    "                f\"Could not find {file.name} in manifest; removing\"\n",
    "            )\n",
    "            file.unlink()\n",
    "\n",
    "    for file in transcript_output_dir.glob(\"./*.txt\"):\n",
    "        if file.name not in transcript_file_names:\n",
    "            pod_scrape_logger.warning(\n",
    "                f\"Could not find {file.name} in manifest; removing\"\n",
    "            )\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def create_manifest(\n",
    "    audio_output_dir, transcript_output_dir, podcast_min_len=5, podcast_max_len=15\n",
    "):\n",
    "    transcript_records = []\n",
    "    for audio, transcript in zip(\n",
    "        sorted(list(audio_output_dir.glob(\"./*.mp3\"))),\n",
    "        sorted(list(transcript_output_dir.glob(\"./*.txt\"))),\n",
    "    ):\n",
    "        assert audio.stem == transcript.stem\n",
    "        with open(transcript, \"r\") as f:\n",
    "            transcript_text = f.read()\n",
    "\n",
    "        transcript_records.append(\n",
    "            {\n",
    "                \"transcript\": transcript_text,\n",
    "                \"len_seconds\": MP3(audio).info.length,\n",
    "                \"len_minutes\": MP3(audio).info.length / 60,\n",
    "                \"audio_path\": audio.resolve(),\n",
    "                \"transcript_path\": transcript.resolve(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    podcast_manifest = (\n",
    "        pd.DataFrame(transcript_records)\n",
    "        .assign(stem=lambda x: x.audio_path.apply(lambda y: y.stem))\n",
    "        .assign(\n",
    "            transcript_len=lambda x: x.transcript.apply(lambda y: len(y.split(\" \")))\n",
    "        )\n",
    "        .query(\"len_minutes >= @podcast_min_len & len_minutes <= @podcast_max_len\")\n",
    "        .assign(\n",
    "            wpm=lambda x: x.apply(lambda y: y.transcript_len / (y.len_minutes), axis=1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return podcast_manifest\n",
    "\n",
    "\n",
    "prune_pairless_transcripts(audio_output_dir, transcript_output_dir)\n",
    "manifest = create_manifest(audio_output_dir, transcript_output_dir)\n",
    "manifest.to_csv(audio_output_dir.parents[0] / \"manifest.csv\", index=False)\n",
    "prune_transcripts_not_in_manifest(manifest, audio_output_dir, transcript_output_dir)\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blog.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b352da5c727154a09156c935f17a9c4d49b2c9c0946f47ddfcca219f38b45087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
