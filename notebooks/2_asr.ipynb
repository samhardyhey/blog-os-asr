{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-09-01 12:59:58 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-09-01 13:00:00 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-09-01 13:00:00 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nemo.collections.nlp.models import PunctuationCapitalizationModel\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import detect_silence\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.ERROR)\n",
    "asr_logger = logging.getLogger(\"asr\")\n",
    "asr_logger.setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model spot-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_models = [e for e in nemo_asr.models.ASRModel.list_available_models() if 'stt_en' in e.pretrained_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of each? https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/models.html\n",
    "test_models = ['stt_en_quartznet15x5', 'stt_en_citrinet_512', 'stt_en_contextnet_512', 'stt_en_conformer_ctc_medium', 'stt_en_conformer_transducer_medium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['stt_en_citrinet_1024',\n",
    " 'stt_en_citrinet_1024_gamma_0_25',\n",
    " 'stt_en_citrinet_256',\n",
    " 'stt_en_citrinet_256_gamma_0_25',\n",
    " 'stt_en_citrinet_512',\n",
    " 'stt_en_citrinet_512_gamma_0_25',\n",
    " 'stt_en_conformer_ctc_large',\n",
    " 'stt_en_conformer_ctc_large_ls',\n",
    " 'stt_en_conformer_ctc_medium',\n",
    " 'stt_en_conformer_ctc_medium_ls',\n",
    " 'stt_en_conformer_ctc_small',\n",
    " 'stt_en_conformer_ctc_small_ls',\n",
    " 'stt_en_conformer_ctc_xlarge',\n",
    " 'stt_en_conformer_transducer_large',\n",
    " 'stt_en_conformer_transducer_large_ls',\n",
    " 'stt_en_conformer_transducer_medium',\n",
    " 'stt_en_conformer_transducer_small',\n",
    " 'stt_en_conformer_transducer_xlarge',\n",
    " 'stt_en_conformer_transducer_xxlarge',\n",
    " 'stt_en_contextnet_1024',\n",
    " 'stt_en_contextnet_1024_mls',\n",
    " 'stt_en_contextnet_256',\n",
    " 'stt_en_contextnet_256_mls',\n",
    " 'stt_en_contextnet_512',\n",
    " 'stt_en_contextnet_512_mls',\n",
    " 'stt_en_jasper10x5dr',\n",
    " 'stt_en_quartznet15x5',\n",
    " 'stt_enes_conformer_ctc_large',\n",
    " 'stt_enes_conformer_transducer_large',\n",
    " 'stt_enes_contextnet_large']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stt_en_citrinet_1024',\n",
       " 'stt_en_citrinet_1024_gamma_0_25',\n",
       " 'stt_en_citrinet_256',\n",
       " 'stt_en_citrinet_256_gamma_0_25',\n",
       " 'stt_en_citrinet_512',\n",
       " 'stt_en_citrinet_512_gamma_0_25',\n",
       " 'stt_en_conformer_ctc_large',\n",
       " 'stt_en_conformer_ctc_large_ls',\n",
       " 'stt_en_conformer_ctc_medium',\n",
       " 'stt_en_conformer_ctc_medium_ls',\n",
       " 'stt_en_conformer_ctc_small',\n",
       " 'stt_en_conformer_ctc_small_ls',\n",
       " 'stt_en_conformer_ctc_xlarge',\n",
       " 'stt_en_conformer_transducer_large',\n",
       " 'stt_en_conformer_transducer_large_ls',\n",
       " 'stt_en_conformer_transducer_medium',\n",
       " 'stt_en_conformer_transducer_small',\n",
       " 'stt_en_conformer_transducer_xlarge',\n",
       " 'stt_en_conformer_transducer_xxlarge',\n",
       " 'stt_en_contextnet_1024',\n",
       " 'stt_en_contextnet_1024_mls',\n",
       " 'stt_en_contextnet_256',\n",
       " 'stt_en_contextnet_256_mls',\n",
       " 'stt_en_contextnet_512',\n",
       " 'stt_en_contextnet_512_mls',\n",
       " 'stt_en_jasper10x5dr',\n",
       " 'stt_en_quartznet15x5',\n",
       " 'stt_enes_conformer_ctc_large',\n",
       " 'stt_enes_conformer_transducer_large',\n",
       " 'stt_enes_contextnet_large']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e.pretrained_model_name for e in pretrained_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_models[0].class_.from_pretrained(model_name=pretrained_models[0].pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "MS = 1000\n",
    "model_name = 'stt_en_conformer_ctc_small'\n",
    "model = nemo_asr.models.ASRModel.from_pretrained(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01794719696044922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d998c2f2a1d4fb1809ee4430a683cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017179250717163086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc019c0ef4a42bbb93e6318992cb556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018062591552734375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d93e3ebb8ca4b99bf064249b28a869a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02406144142150879,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e434dd26cfe04454be305fff09725d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017319679260253906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fe509b10484239b555cee6a8895afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017482995986938477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfeb63f6db84058af8c74cccb1f5161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017305374145507812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68e85b4a38d4962bdf7a47097b6fe0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/tmp/tmpcs6gqizs/memory_test_fragment.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017352819442749023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Transcribing",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1577b4ca8746f5afc3b8ace18ad533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tempfile\n",
    "import nvsmi\n",
    "from pathlib import Path\n",
    "import time\n",
    "import torch\n",
    "\n",
    "model_memory_footprint = nvsmi.get_gpu_processes()[0].used_memory\n",
    "audio_segment = AudioSegment.from_wav('/home/blog-os-asr/output/temp_dir/rewilding-the-scottish-highlands.wav')\n",
    "slice_intervals = [(0, e*MS) for e in list(range(0,135,15))][1:]\n",
    "\n",
    "memory_usage_records = []\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    for interval in slice_intervals:\n",
    "        save_message = audio_segment[interval[0]:interval[1]].export(Path(temp_dir) / 'memory_test_fragment.wav', format='wav')\n",
    "        (Path(temp_dir) / 'memory_test_fragment.wav').exists()\n",
    "        [str(Path(temp_dir) / 'memory_test_fragment.wav')]\n",
    "        before = time.time()\n",
    "        transcription = model.transcribe(paths2audio_files=[str(Path(temp_dir) / 'memory_test_fragment.wav')], batch_size=BATCH_SIZE)\n",
    "        after = time.time()\n",
    "        memory_usage_records.append({'transcript': transcription, 'memory_usage': nvsmi.get_gpu_processes()[0].used_memory, 'time_elapsed': after-before})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"but we begin with jeremy leggate former professor at imperial college and oxford with his massive project in a world famous setting highland's rewlding is a new type of company it's a mass ownership company and it's going to do its level best to accelerate nature recovery in the highlands of scotland so as to contribute to repair of climate meltdown and biodiversity collapse thats some remits't it jeremy legget could you place us where are we i know down below is lone but loness much to my surprise is very very long so where are we we' are halfway along lockness about sixteen miles from a fairly big city invenness the capital of the highlands of scotland and despite the proximity to that city we're in a a really wild place there's one thousand two hundred acres on this estate that we're managing and not many footpaths and there's a lot of genuine wildland in our mixed habitats of native woodlands peedlands pasture heathland and conniferous plantations how long is lochnes\"]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asr import transcribe_mono\n",
    "\n",
    "transcription = transcribe_mono(\n",
    "    \"../output/radio_national_podcasts/audio/rewilding-the-scottish-highlands.mp3\"\n",
    ")\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_formatted_words_all = []\n",
    "for idx, record in transcription.head(10).iterrows():\n",
    "    time_formatted_words = _format_word_timestamps(record.asr_outputs, record.start)\n",
    "\n",
    "    # 5.0 apply punctuation to each output\n",
    "    punctuated_sequence = punct_model.add_punctuation_capitalization(\n",
    "        [\" \".join(e[\"word\"] for e in time_formatted_words)]\n",
    "    )[0]\n",
    "\n",
    "    # if len(punctuated_sequence.split(\" \")) == len(time_formatted_words):\n",
    "    #     # easy case, where punctuated output len matches input len; assign directly\n",
    "    #     punctuated_sequence_joined = (\n",
    "    #         pd.DataFrame(time_formatted_words)\n",
    "    #         .assign(word=punctuated_sequence.split(\" \"))\n",
    "    #         .assign(speakerTag=record.speaker)\n",
    "    #         .to_dict(orient=\"records\")\n",
    "    #     )\n",
    "    #     time_formatted_words_all.append(punctuated_sequence_joined)\n",
    "    # else:\n",
    "    #     # otherwise.. pad the difference? changes should be limited to immediately proceeding fullstops, commas, question marks\n",
    "    #     # https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/nlp/punctuation_and_capitalization.html\n",
    "    #     print(\"Punctuated outputs not the same length as input\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('p38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb0121aec9e40b71ec9730e04f00957539fc5aa06febb00ef12b9b6cf43c877e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
